 spring.application.name=useradmin
spring.profiles.active=dev
spring.cloud.config.label=dev
spring.cloud.config.profile=dev
spring.cloud.config.discovery.enabled=true
spring.cloud.config.discovery.service-id=config-server
server.port=8763

spring.rabbitmq.username=guest
spring.rabbitmq.password=guest

#kafka
spring.kafka.client-id=${spring.application.name}
spring.kafka.listener.ack-mode=batch
spring.kafka.listener.concurrency=2
spring.kafka.listener.poll-timeout=5000
spring.kafka.bootstrap-servers=127.0.0.1:9092
spring.kafka.consumer.group-id=test
#ensure the new consumer group will get the messages we just sent, because
#the container might start after the sends have completed.
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=false

spring.kafka.producer.buffer-memory=8388608

spring.kafka.producer.batch-size=102400
spring.kafka.template.default-topic=test
#spring.kafka.consumer.properties.partition.assignment.strategy=org.apache.kafka.clients.consumer.RoundRobinAssignor
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

#logging.file=${spring.application.name}.log
#logging.path=/
logging.level.eureka.config=info
logging.level.eureka.controller=debug
logging.kafka.topic=log-${spring.application.name}
logging.kafka.servers=${spring.kafka.bootstrap-servers}